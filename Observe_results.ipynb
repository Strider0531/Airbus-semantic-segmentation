{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from skimage.morphology import binary_opening, disk\n",
    "from keras.models import load_model\n",
    "from matplotlib.cm import get_cmap\n",
    "from skimage.io import imread\n",
    "\n",
    "from utils import masks_as_color, multi_rle_encode\n",
    "from configs import TRAIN_DATA_FOLDER, TEST_DATA_FOLDER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get validation set for prediction testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masks = pd.read_csv(os.path.join('data', 'train_ship_segmentations_v2.csv'))\n",
    "valid_df = pd.read_csv('data/valid.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the root to train/test dataframes\n",
    "train_image_dir = os.path.join('data', TRAIN_DATA_FOLDER)\n",
    "test_image_dir = os.path.join('data', TEST_DATA_FOLDER)\n",
    "\n",
    "# Open U-net model\n",
    "fullres_model = load_model('fullres_model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Viewing results\n",
    "Results will be save at the main folder to validation.png"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def raw_prediction(img, path=test_image_dir):\n",
    "    c_img = imread(os.path.join(path, c_img_name))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    return cur_seg, c_img[0]\n",
    "\n",
    "def smooth(cur_seg):\n",
    "    return binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n",
    "\n",
    "def predict(img, path=test_image_dir):\n",
    "    cur_seg, c_img = raw_prediction(img, path=path)\n",
    "    return smooth(cur_seg), c_img\n",
    "\n",
    "## Get a sample of each group of ship count\n",
    "samples = valid_df.groupby('ships').apply(lambda x: x.sample(1))\n",
    "fig, m_axs = plt.subplots(samples.shape[0], 4, figsize = (15, samples.shape[0]*4))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2, ax3, ax4), c_img_name in zip(m_axs, samples.ImageId.values):\n",
    "    first_seg, first_img = raw_prediction(c_img_name, train_image_dir)\n",
    "    ax1.imshow(first_img)\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(first_seg[:, :, 0], cmap=get_cmap('jet'))\n",
    "    ax2.set_title('Model Prediction')\n",
    "    reencoded = masks_as_color(multi_rle_encode(smooth(first_seg)[:, :, 0]))\n",
    "    ax3.imshow(reencoded)\n",
    "    ax3.set_title('Prediction Masks')\n",
    "    ground_truth = masks_as_color(masks.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels'])\n",
    "    ax4.imshow(ground_truth)\n",
    "    ax4.set_title('Ground Truth')\n",
    "\n",
    "fig.savefig('validation.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}